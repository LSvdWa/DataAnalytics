{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#from numpy.core.numeric import infty\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install plotly\n",
    "\n",
    "!pip install scikit-learn # non-depreceated sklearn"
   ],
   "id": "9f9cc532a184920b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "TASK 1",
   "id": "2c742fe5da58a325"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "# read the csv and make it a pandas.DataFrame\n",
    "frame = pd.DataFrame(pd.read_csv(\"./blood_transfusion.csv\"))\n",
    "frame.describe(include='all') # 5 columns, 4 numerical, class is nominal (1 or 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# TODO: visualise, understand, story",
   "id": "1a108e72ae895ecd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "TASK 2",
   "id": "f3ad8613b85917f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "preprocessed = frame.copy() \n",
    "preprocessed = (preprocessed-preprocessed.min())/(preprocessed.max()-preprocessed.min()) # Normalization\n",
    "# It also normalizes the class, but because class is either 1 or 0, the formula does not change the class \n",
    "preprocessed.describe()"
   ],
   "id": "7a917225e85e418c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "TASK 3",
   "id": "41518569b23bfe5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_s, X_test_s, Y_train_s, Y_test_s = train_test_split(\n",
    "    preprocessed.drop('class', axis=1), preprocessed['class'], test_size=0.33, random_state=1) # small test_size\n",
    "X_train_l, X_test_l, Y_train_l, Y_test_l = train_test_split(\n",
    "    preprocessed.drop('class', axis=1), preprocessed['class'], test_size=0.66, random_state=1) # large test_size\n",
    "# random state for reproducibility"
   ],
   "id": "5efca73ed556e355",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "TASK 4 & 5",
   "id": "25d2e5f6c9684691"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "#5.1 Confusion matrix\n",
    "def confusionmatrix(predicted_y, real_y): # it works, im confused :) \\j\n",
    "    \"\"\"\n",
    "    This function calculates and prints the confusion matrix.\n",
    "    :param predicted_y: list: predicted classes for the test data \n",
    "    :param real_y: list: real classes of the test data\n",
    "    :return: prints the confusion matrix, returns nothing\n",
    "    \"\"\"\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for index,_ in enumerate(predicted_y):\n",
    "        if predicted_y[index] == 1: \n",
    "            if predicted_y[index] == real_y[index]: \n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        elif predicted_y[index] == 0:\n",
    "            if predicted_y[index] == real_y[index]: \n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "    print(f\"\\t P \\t\\t N \\n T \\t {tp} \\t\\t {tn} \\n F \\t {fp} \\t\\t {fn} \\n\")\n",
    "\n",
    "def accuracy_checker(X_test, y_test, pred, mode=\"basic\"):\n",
    "    \"\"\"\n",
    "    This function checks the accuracy of the predicted classes against the real classes.\n",
    "    :param X_test: pandas.DataFrame: the test data to be classified\n",
    "    :param y_test: pandas.Series: the real classes of the test data\n",
    "    :param pred: predictor class: the method used to classify the test data\n",
    "    :param mode: string: way to evaluate the results\n",
    "    :return: prints the results, returns nothing\n",
    "    \"\"\"\n",
    "    num, total = 0, 0\n",
    "    predicted, true = [], []\n",
    "    for index, row in X_test.iterrows():\n",
    "        p = pred.predict(X_test.loc[[index]])\n",
    "        q = list(y_test.loc[[index]])\n",
    "        if p == q:\n",
    "            num += 1\n",
    "        total += 1\n",
    "        predicted.append(p)\n",
    "        true.append(q)\n",
    "    \n",
    "    if mode == \"basic\":\n",
    "        print(f\"Accuracy: {num/total*100:.2f}%\")\n",
    "    elif mode == \"classification_report\":\n",
    "        print(classification_report(true, predicted))\n",
    "    elif mode == \"confusion_matrix\":\n",
    "        confusionmatrix(true, predicted)\n",
    "    elif mode == \"fbeta\":\n",
    "        print(\"average=macro:\", fbeta_score(true, predicted, average='macro', beta=0.5))\n",
    "        print(\"average=weighted:\", fbeta_score(true, predicted, average='weighted', beta=0.5))\n",
    "        print(\"average=None:\", fbeta_score(true, predicted, average=None, beta=0.5))\n",
    "\n",
    "# 4.1 KNN\n",
    "class KNN:    \n",
    "    def __init__(self, k=5):\n",
    "        \"\"\"\n",
    "        initializes an instance of the KNN class\n",
    "        :param k: int: number of neighbors\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        fits the KNN class\n",
    "        :param X: pandas.DataFrame: the train data\n",
    "        :param y: pandas.Series: the classes of the train data\n",
    "        :return: a fitted instance of the KNN class\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        return self\n",
    "    \n",
    "    def euclidean_distance(self, a, b):\n",
    "        \"\"\"\n",
    "        This function calculates the euclidean distance between two datapoints.\n",
    "        :param a: list: the first datapoint\n",
    "        :param b: list: the second datapoint\n",
    "        :return: float: the euclidean distance between the datapoints\n",
    "        \"\"\"\n",
    "        distance = 0\n",
    "        for index, _ in enumerate(a):\n",
    "            distance += (a[index] - b[index]) ** 2\n",
    "        distance = distance**0.5\n",
    "        return distance    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        predicts the class of the test data\n",
    "        :param X_test: pandas.DataFrame: the test data\n",
    "        :return: list: the predicted classes\n",
    "        \"\"\"\n",
    "        test_y = list([0 for _ in range(X_test.shape[0])])\n",
    "        for index, (_,test_row) in enumerate(X_test.iterrows()):\n",
    "            distances = []\n",
    "            for _, train_row in self.X_train.iterrows():\n",
    "                test_values = list(test_row)  \n",
    "                train_values = list(train_row)\n",
    "                distance = self.euclidean_distance(test_values, train_values)\n",
    "                distances.append(distance)\n",
    "            nearest_neighbours = sorted(range(len(distances)), key=lambda i: distances[i])[:self.k]\n",
    "            neighbor_labels = self.y_train.iloc[nearest_neighbours]\n",
    "            predicted_label = round(neighbor_labels.mean())\n",
    "            test_y[index] = predicted_label\n",
    "        return test_y\n",
    "\n",
    "# from accuracy it appears that k=5 is best for small set and k=[2,4,9] are all best for large set, for 1<=k<=9\n",
    "knn_s = KNN(5)\n",
    "knn_s.fit(X_train_s, Y_train_s)\n",
    "print(\"For class knn:\")\n",
    "accuracy_checker(X_test_s, Y_test_s, knn_s)\n",
    "\n",
    "# 4.2 nbc\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nbc = GaussianNB()\n",
    "nbc.fit(X_train_s, Y_train_s)\n",
    "print(\"For nbc:\")\n",
    "accuracy_checker(X_test_s, Y_test_s, nbc)\n",
    "\n",
    "# 4.3 svc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "svc = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "svc.fit(X_train_s, Y_train_s)\n",
    "print(\"For svc:\")\n",
    "accuracy_checker(X_test_s, Y_test_s, svc)\n",
    "\n",
    "# 4.4 mlp\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=1, max_iter=250).fit(X_train_s, Y_train_s)\n",
    "print(\"For mlp:\")\n",
    "accuracy_checker(X_test_s, Y_test_s, mlp)"
   ],
   "id": "5fd32bd75029c3fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "knn_s = KNN(5)\n",
    "knn_s.fit(X_train_s, Y_train_s)\n",
    "knn_l = KNN(5)\n",
    "knn_l.fit(X_train_l, Y_train_l)\n",
    "preds = [nbc, svc, mlp, knn_s]\n",
    "modes = [\"confusion_matrix\", \"classification_report\", \"fbeta\"]\n",
    "for mode in modes:\n",
    "    for pred in preds:\n",
    "        pred_string = \"\"\n",
    "        if pred == svc: pred_string = \"svc\"\n",
    "        elif pred == mlp: pred_string = \"mlp\"\n",
    "        elif pred == nbc: pred_string = \"nbc\"\n",
    "        elif pred == knn_s or pred == knn_l: pred_string = \"knn\"\n",
    "        print(f\"{mode} for {pred_string} with small test data size:\")\n",
    "        accuracy_checker(X_test_s, Y_test_s, pred, mode=mode)            \n",
    "        print(f\"\\n{mode} for {pred_string} with large test data size:\")\n",
    "        accuracy_checker(X_test_l, Y_test_l, pred, mode=mode)\n",
    "        print(\"-----------------------------------------\")"
   ],
   "id": "8aadb811fdda4bdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ee48293a89ef8b5f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
