{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:07:21.270077Z",
     "start_time": "2025-10-01T18:07:05.451863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#from numpy.core.numeric import infty\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install plotly\n",
    "\n",
    "!pip install scikit-learn # non-depreceated sklearn"
   ],
   "id": "9f9cc532a184920b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\friso\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\friso\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\friso\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\friso\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\friso\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\friso\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\friso\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\friso\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\friso\\anaconda3\\lib\\site-packages (from plotly) (8.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Task1",
   "id": "2c742fe5da58a325"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-01T18:07:21.299673Z",
     "start_time": "2025-10-01T18:07:21.270077Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "# read the csv and make it a pandas.DataFrame\n",
    "frame = pd.DataFrame(pd.read_csv(\"./blood_transfusion.csv\"))\n",
    "frame.describe(include='all') # 5 columns"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       months_since_last_donation  total_number_of_donations  \\\n",
       "count                  748.000000                 748.000000   \n",
       "mean                     9.506684                   5.514706   \n",
       "std                      8.095396                   5.839307   \n",
       "min                      0.000000                   1.000000   \n",
       "25%                      2.750000                   2.000000   \n",
       "50%                      7.000000                   4.000000   \n",
       "75%                     14.000000                   7.000000   \n",
       "max                     74.000000                  50.000000   \n",
       "\n",
       "       total_blood_donated  months_since_first_donation       class  \n",
       "count           748.000000                   748.000000  748.000000  \n",
       "mean           1378.676471                    34.282086    0.237968  \n",
       "std            1459.826781                    24.376714    0.426124  \n",
       "min             250.000000                     2.000000    0.000000  \n",
       "25%             500.000000                    16.000000    0.000000  \n",
       "50%            1000.000000                    28.000000    0.000000  \n",
       "75%            1750.000000                    50.000000    0.000000  \n",
       "max           12500.000000                    98.000000    1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_since_last_donation</th>\n",
       "      <th>total_number_of_donations</th>\n",
       "      <th>total_blood_donated</th>\n",
       "      <th>months_since_first_donation</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.506684</td>\n",
       "      <td>5.514706</td>\n",
       "      <td>1378.676471</td>\n",
       "      <td>34.282086</td>\n",
       "      <td>0.237968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.095396</td>\n",
       "      <td>5.839307</td>\n",
       "      <td>1459.826781</td>\n",
       "      <td>24.376714</td>\n",
       "      <td>0.426124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>12500.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:07:21.304184Z",
     "start_time": "2025-10-01T18:07:21.299673Z"
    }
   },
   "cell_type": "code",
   "source": "# visualise, understand, story",
   "id": "1a108e72ae895ecd",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Task2",
   "id": "f3ad8613b85917f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:07:21.323259Z",
     "start_time": "2025-10-01T18:07:21.306206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preprocessed = frame.copy() \n",
    "preprocessed = (preprocessed-preprocessed.min())/(preprocessed.max()-preprocessed.min()) # Normalization\n",
    "preprocessed.describe()"
   ],
   "id": "7a917225e85e418c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       months_since_last_donation  total_number_of_donations  \\\n",
       "count                  748.000000                 748.000000   \n",
       "mean                     0.128469                   0.092137   \n",
       "std                      0.109397                   0.119170   \n",
       "min                      0.000000                   0.000000   \n",
       "25%                      0.037162                   0.020408   \n",
       "50%                      0.094595                   0.061224   \n",
       "75%                      0.189189                   0.122449   \n",
       "max                      1.000000                   1.000000   \n",
       "\n",
       "       total_blood_donated  months_since_first_donation       class  \n",
       "count           748.000000                   748.000000  748.000000  \n",
       "mean              0.092137                     0.336272    0.237968  \n",
       "std               0.119170                     0.253924    0.426124  \n",
       "min               0.000000                     0.000000    0.000000  \n",
       "25%               0.020408                     0.145833    0.000000  \n",
       "50%               0.061224                     0.270833    0.000000  \n",
       "75%               0.122449                     0.500000    0.000000  \n",
       "max               1.000000                     1.000000    1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_since_last_donation</th>\n",
       "      <th>total_number_of_donations</th>\n",
       "      <th>total_blood_donated</th>\n",
       "      <th>months_since_first_donation</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.128469</td>\n",
       "      <td>0.092137</td>\n",
       "      <td>0.092137</td>\n",
       "      <td>0.336272</td>\n",
       "      <td>0.237968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.109397</td>\n",
       "      <td>0.119170</td>\n",
       "      <td>0.119170</td>\n",
       "      <td>0.253924</td>\n",
       "      <td>0.426124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.037162</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 168
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "TASK 3",
   "id": "41518569b23bfe5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:07:21.331752Z",
     "start_time": "2025-10-01T18:07:21.324269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_s, X_test_s, Y_train_s, Y_test_s = train_test_split(\n",
    "    preprocessed.drop('class', axis=1), preprocessed['class'], test_size=0.33, random_state=1) # small test_size\n",
    "X_train_l, X_test_l, Y_train_l, Y_test_l = train_test_split(\n",
    "    preprocessed.drop('class', axis=1), preprocessed['class'], test_size=0.66, random_state=1) # large test_size\n",
    "# random state for reproducibility"
   ],
   "id": "5efca73ed556e355",
   "outputs": [],
   "execution_count": 169
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Task 4",
   "id": "25d2e5f6c9684691"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:17:36.060901Z",
     "start_time": "2025-10-01T18:17:31.547784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "#5.1 Confusion matrix\n",
    "def confusionmatrix(predicted_y, real_y): # it works, im confused :)\n",
    "    \"\"\"\n",
    "    This function calculates and prints the confusion matrix.\n",
    "    :param predicted_y: list: predicted classes for the test data \n",
    "    :param real_y: list: real classes of the test data\n",
    "    :return: prints the confusion matrix, returns nothing\n",
    "    \"\"\"\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for index,_ in enumerate(predicted_y):\n",
    "        if predicted_y[index] == 1: \n",
    "            if predicted_y[index] == real_y[index]: \n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        elif predicted_y[index] == 0:\n",
    "            if predicted_y[index] == real_y[index]: \n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "    print(f\"\\t P \\t\\t N \\n T \\t {tp} \\t\\t {tn} \\n F \\t {fp} \\t\\t {fn} \\n\")\n",
    "\n",
    "def accuracy_checker(y_test, pred, mode=\"basic\", X_test=None, y_predicted=None, knn=False):\n",
    "    \"\"\"\n",
    "    This function checks the accuracy of the predicted classes against the real classes.\n",
    "    :param X_test: pandas.DataFrame: the test data to be classified\n",
    "    :param y_predicted: list: predicted classes for the test data\n",
    "    :param y_test: pandas.Series: the real classes of the test data\n",
    "    :param pred: predictor class: the method used to classify the test data\n",
    "    :param mode: string: way to evaluate the results\n",
    "    :return: prints the results, returns nothing\n",
    "    \"\"\"\n",
    "    num, total = 0, 0\n",
    "    predicted, true = [], []\n",
    "    if not knn:\n",
    "        for index, row in X_test.iterrows():\n",
    "            p = pred.predict(X_test.loc[[index]])\n",
    "            q = list(y_test.loc[[index]])\n",
    "            if p == q:\n",
    "                num += 1\n",
    "            total += 1\n",
    "            predicted.append(p)\n",
    "            true.append(q)\n",
    "    else: \n",
    "        predicted = y_predicted\n",
    "        true = list(y_test)\n",
    "        for index, _ in enumerate(predicted):\n",
    "            if predicted[index] == true[index]: \n",
    "                num += 1\n",
    "            total += 1\n",
    "        \n",
    "    if mode == \"basic\":\n",
    "        print(f\"Accuracy: {num/total*100:.2f}%\")\n",
    "    elif mode == \"classification_report\":\n",
    "        print(classification_report(true, predicted))\n",
    "    elif mode == \"confusion_matrix\":\n",
    "        confusionmatrix(true, predicted)\n",
    "    elif mode == \"fbeta\":\n",
    "        print(\"average=macro:\", fbeta_score(true, predicted, average='macro', beta=0.5))\n",
    "        print(\"average=weighted:\", fbeta_score(true, predicted, average='weighted', beta=0.5))\n",
    "        print(\"average=None:\", fbeta_score(true, predicted, average=None, beta=0.5))\n",
    "\n",
    "# 4.1 KNN\n",
    "def manhattan_distance(a, b):\n",
    "    \"\"\"\n",
    "    This function calculates the manhattan distance between two datapoints.\n",
    "    :param a: list: the first datapoint\n",
    "    :param b: list: the second datapoint\n",
    "    :return: float: the manhattan distance between the datapoints\n",
    "    \"\"\"\n",
    "    distance = 0\n",
    "    for index, _ in enumerate(a):\n",
    "        distance += ((a[index] - b[index]) ** 2) ** 0.5\n",
    "    return distance      \n",
    "\n",
    "def KNN_classifier(k, train_x, train_y, test_x):\n",
    "    \"\"\"\n",
    "    This function trains the KNN classifier on the training data and predicts the class of the test data.\n",
    "    :param k: int: the number of neighbors\n",
    "    :param train_x: pandas.DataFrame: the train data\n",
    "    :param train_y: pandas.Series: the corresponding classes of the train data\n",
    "    :param test_x: pandas.DataFrame: the test data\n",
    "    :return: list: the predicted classes of the test data\n",
    "    \"\"\"\n",
    "    test_y = list([0 for _ in range(test_x.shape[0])])\n",
    "    for index, (_,test_row) in enumerate(test_x.iterrows()):\n",
    "        distances = []\n",
    "        for _, train_row in train_x.iterrows():\n",
    "            test_values = list(test_row)  \n",
    "            train_values = list(train_row)\n",
    "            distance = manhattan_distance(test_values, train_values)\n",
    "            distances.append(distance)\n",
    "        nearest_neighbours = sorted(range(len(distances)), key=lambda i: distances[i])[:k]\n",
    "        neighbor_labels = train_y.iloc[nearest_neighbours]\n",
    "        predicted_label = round(neighbor_labels.mean())\n",
    "        test_y[index] = predicted_label\n",
    "    return test_y\n",
    "\n",
    "y_predicted = KNN_classifier(5, X_train_s, Y_train_s, X_test_s)\n",
    "print(\"For knn:\")\n",
    "accuracy_checker(Y_test_s, \"knn\", y_predicted=y_predicted, knn=True)\n",
    "\n",
    "# 4.2 nbc\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nbc = GaussianNB()\n",
    "nbc.fit(X_train_s, Y_train_s)\n",
    "print(\"For nbc:\")\n",
    "accuracy_checker(Y_test_s, nbc, X_test=X_test_s)\n",
    "\n",
    "# 4.3 svc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "svc = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "svc.fit(X_train_s, Y_train_s)\n",
    "print(\"For svc:\")\n",
    "accuracy_checker(Y_test_s, svc, X_test=X_test_s)\n",
    "\n",
    "# 4.4 mlp\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=1, max_iter=250).fit(X_train_s, Y_train_s)\n",
    "print(\"For mlp:\")\n",
    "accuracy_checker(Y_test_s, mlp, X_test=X_test_s)"
   ],
   "id": "5fd32bd75029c3fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For knn:\n",
      "Accuracy: 77.73%\n",
      "For nbc:\n",
      "Accuracy: 74.90%\n",
      "For svc:\n",
      "Accuracy: 76.11%\n",
      "For mlp:\n",
      "Accuracy: 76.92%\n"
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:24:16.986108Z",
     "start_time": "2025-10-01T18:24:03.797755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Y_predicted_s = KNN_classifier(5, X_train_s, Y_train_s, X_test_s)\n",
    "Y_predicted_l = KNN_classifier(5, X_train_l, Y_train_l, X_test_l)\n",
    "preds = [nbc, svc, mlp, \"knn\"]\n",
    "modes = [\"confusion_matrix\", \"classification_report\", \"fbeta\"]\n",
    "for mode in modes:\n",
    "    for pred in preds:\n",
    "        if pred == \"knn\":\n",
    "            print(f\"{mode} for {pred} with small test data size:\")\n",
    "            accuracy_checker(Y_test_s, pred, mode=mode, y_predicted=Y_predicted_s, knn=True)\n",
    "            print(f\"\\n{mode} for {pred} with large test data size:\")\n",
    "            accuracy_checker(Y_test_l, pred, mode=mode, y_predicted=Y_predicted_l, knn=True)\n",
    "            print(\"-----------------------------------------\")\n",
    "        else:\n",
    "            pred_string = \"\"\n",
    "            if pred == svc: pred_string = \"svc\"\n",
    "            elif pred == mlp: pred_string = \"mlp\"\n",
    "            elif pred == nbc: pred_string = \"nbc\"\n",
    "            print(f\"{mode} for {pred_string} with small test data size:\")\n",
    "            accuracy_checker(Y_test_s, pred, mode=mode, X_test=X_test_s)            \n",
    "            print(f\"\\n{mode} for {pred_string} with large test data size:\")\n",
    "            accuracy_checker(Y_test_l, pred, mode=mode, X_test=X_test_l)\n",
    "            print(\"-----------------------------------------\")"
   ],
   "id": "8aadb811fdda4bdb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix for nbc with small test data size:\n",
      "\t P \t\t N \n",
      " T \t 0 \t\t 0 \n",
      " F \t 0 \t\t 0 \n",
      "\n",
      "\n",
      "confusion_matrix for nbc with large test data size:\n",
      "\t P \t\t N \n",
      " T \t 0 \t\t 0 \n",
      " F \t 0 \t\t 0 \n",
      "\n",
      "-----------------------------------------\n",
      "confusion_matrix for svc with small test data size:\n",
      "\t P \t\t N \n",
      " T \t 0 \t\t 0 \n",
      " F \t 0 \t\t 0 \n",
      "\n",
      "\n",
      "confusion_matrix for svc with large test data size:\n",
      "\t P \t\t N \n",
      " T \t 0 \t\t 0 \n",
      " F \t 0 \t\t 0 \n",
      "\n",
      "-----------------------------------------\n",
      "confusion_matrix for mlp with small test data size:\n",
      "\t P \t\t N \n",
      " T \t 0 \t\t 0 \n",
      " F \t 0 \t\t 0 \n",
      "\n",
      "\n",
      "confusion_matrix for mlp with large test data size:\n",
      "\t P \t\t N \n",
      " T \t 0 \t\t 0 \n",
      " F \t 0 \t\t 0 \n",
      "\n",
      "-----------------------------------------\n",
      "confusion_matrix for knn with small test data size:\n",
      "\t P \t\t N \n",
      " T \t 21 \t\t 171 \n",
      " F \t 42 \t\t 13 \n",
      "\n",
      "\n",
      "confusion_matrix for knn with large test data size:\n",
      "\t P \t\t N \n",
      " T \t 30 \t\t 342 \n",
      " F \t 86 \t\t 36 \n",
      "\n",
      "-----------------------------------------\n",
      "classification_report for nbc with small test data size:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.96      0.85       184\n",
      "         1.0       0.53      0.13      0.21        63\n",
      "\n",
      "    accuracy                           0.75       247\n",
      "   macro avg       0.65      0.54      0.53       247\n",
      "weighted avg       0.70      0.75      0.69       247\n",
      "\n",
      "\n",
      "classification_report for nbc with large test data size:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.95      0.86       378\n",
      "         1.0       0.53      0.17      0.26       116\n",
      "\n",
      "    accuracy                           0.77       494\n",
      "   macro avg       0.66      0.56      0.56       494\n",
      "weighted avg       0.73      0.77      0.72       494\n",
      "\n",
      "-----------------------------------------\n",
      "classification_report for svc with small test data size:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.99      0.86       184\n",
      "         1.0       0.83      0.08      0.14        63\n",
      "\n",
      "    accuracy                           0.76       247\n",
      "   macro avg       0.80      0.54      0.50       247\n",
      "weighted avg       0.78      0.76      0.68       247\n",
      "\n",
      "\n",
      "classification_report for svc with large test data size:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      1.00      0.88       378\n",
      "         1.0       0.92      0.10      0.19       116\n",
      "\n",
      "    accuracy                           0.79       494\n",
      "   macro avg       0.85      0.55      0.53       494\n",
      "weighted avg       0.82      0.79      0.72       494\n",
      "\n",
      "-----------------------------------------\n",
      "classification_report for mlp with small test data size:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.99      0.87       184\n",
      "         1.0       0.88      0.11      0.20        63\n",
      "\n",
      "    accuracy                           0.77       247\n",
      "   macro avg       0.82      0.55      0.53       247\n",
      "weighted avg       0.79      0.77      0.69       247\n",
      "\n",
      "\n",
      "classification_report for mlp with large test data size:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.98      0.87       378\n",
      "         1.0       0.70      0.12      0.21       116\n",
      "\n",
      "    accuracy                           0.78       494\n",
      "   macro avg       0.74      0.55      0.54       494\n",
      "weighted avg       0.76      0.78      0.72       494\n",
      "\n",
      "-----------------------------------------\n",
      "classification_report for knn with small test data size:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.93      0.86       184\n",
      "         1.0       0.62      0.33      0.43        63\n",
      "\n",
      "    accuracy                           0.78       247\n",
      "   macro avg       0.71      0.63      0.65       247\n",
      "weighted avg       0.76      0.78      0.75       247\n",
      "\n",
      "\n",
      "classification_report for knn with large test data size:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.90      0.85       378\n",
      "         1.0       0.45      0.26      0.33       116\n",
      "\n",
      "    accuracy                           0.75       494\n",
      "   macro avg       0.63      0.58      0.59       494\n",
      "weighted avg       0.72      0.75      0.73       494\n",
      "\n",
      "-----------------------------------------\n",
      "fbeta for nbc with small test data size:\n",
      "average=macro: 0.5605332806925192\n",
      "average=weighted: 0.6758164121413446\n",
      "average=None: [0.79586331 0.32520325]\n",
      "\n",
      "fbeta for nbc with large test data size:\n",
      "average=macro: 0.5952865102281508\n",
      "average=weighted: 0.7131081127583628\n",
      "average=None: [0.81743869 0.37313433]\n",
      "-----------------------------------------\n",
      "fbeta for svc with small test data size:\n",
      "average=macro: 0.5421973246826064\n",
      "average=weighted: 0.6670384637274106\n",
      "average=None: [0.79703833 0.28735632]\n",
      "\n",
      "fbeta for svc with large test data size:\n",
      "average=macro: 0.5879980141491871\n",
      "average=weighted: 0.7104353646262284\n",
      "average=None: [0.81885317 0.35714286]\n",
      "-----------------------------------------\n",
      "fbeta for mlp with small test data size:\n",
      "average=macro: 0.5855263157894737\n",
      "average=weighted: 0.6918815256765396\n",
      "average=None: [0.80263158 0.36842105]\n",
      "\n",
      "fbeta for mlp with large test data size:\n",
      "average=macro: 0.5875424048247267\n",
      "average=weighted: 0.7097381163483094\n",
      "average=None: [0.81794195 0.35714286]\n",
      "-----------------------------------------\n",
      "fbeta for knn with small test data size:\n",
      "average=macro: 0.6764638831221745\n",
      "average=weighted: 0.7493703962892009\n",
      "average=None: [0.82528958 0.52763819]\n",
      "\n",
      "fbeta for knn with large test data size:\n",
      "average=macro: 0.6064593301435407\n",
      "average=weighted: 0.7187493946496717\n",
      "average=None: [0.81818182 0.39473684]\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:07:30.756129Z",
     "start_time": "2025-10-01T18:07:30.752563Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ee48293a89ef8b5f",
   "outputs": [],
   "execution_count": 171
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
