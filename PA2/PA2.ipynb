{
 "cells": [
  {
   "cell_type": "code",
   "id": "6198313a0fd8ef21",
   "metadata": {},
   "source": [
    "from numpy.core.numeric import infty\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install plotly\n",
    "\n",
    "!pip install scikit-learn # non-depreaceated sklearn"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c04bec9720cf8181",
   "metadata": {},
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "id": "569340ce255da6ee",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "# read the csv and make it a pandas.DataFrame\n",
    "frame = pd.DataFrame(pd.read_csv(\"./online_shoppers_intention.csv\"))\n",
    "frame.describe(include='all') # 18 columns, including 2 categorical: Month & VisitorType, and two boolean: Weekend & Revenue"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "67c526a1fa33357c",
   "metadata": {},
   "source": [
    "Verhaaltje van ~1min"
   ]
  },
  {
   "cell_type": "code",
   "id": "619404bddacffcd3",
   "metadata": {},
   "source": [
    "#visualisation\n",
    "# split the Browser 13 users from the rest\n",
    "frame13 = frame.loc[frame.Browser == 13]\n",
    "frameOther = frame.loc[frame.Browser != 13]\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "# make a small dataframe with normalized data for plotting\n",
    "def create_distribution(frameColumn):\n",
    "    return pd.DataFrame({\n",
    "        'Browser 13': frame13[frameColumn].value_counts(normalize=True),\n",
    "        'Other browsers': frameOther[frameColumn].value_counts(normalize=True)\n",
    "    }).reset_index().rename(columns={'index': col})\n",
    "# plot all these columns\n",
    "for col in ['VisitorType', 'Weekend', 'Revenue']:\n",
    "    distribution = create_distribution(col)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(x=distribution[col], y=distribution['Browser 13'], name='Browser 13'))\n",
    "    fig.add_trace(go.Bar(x=distribution[col], y=distribution['Other browsers'], name='Other browsers'))\n",
    "    fig.update_layout(barmode='group', title=f'{col} Distribution')\n",
    "    fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e1d6f54fce662810",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "id": "b3be118550c59a04",
   "metadata": {},
   "source": [
    "#Prepositioning op basis van algoritmes in task 3\n",
    "# Preprocess using dropna AND change all string types to an integer\n",
    "def Month_to_num(x):\n",
    "    months = {\n",
    "        \"Jan\": 1, \"Feb\": 2, \"Mar\": 3, \"Apr\": 4,\n",
    "        \"May\": 5, \"June\": 6, \"Jul\": 7, \"Aug\": 8,\n",
    "        \"Sep\": 9, \"Oct\": 10, \"Nov\": 11, \"Dec\": 12, \"Returning_Visitor\": 1, \"Old_Visitor\": 2, \"New_Visitor\": 3, \"Other\": 4, True: 1, False: 0}\n",
    "    if x not in months:\n",
    "        raise ValueError(f\"Invalid month string: {x}\")\n",
    "    return months[x]\n",
    "\n",
    "\n",
    "addlist = []\n",
    "preprocessed = (frame.copy().dropna())\n",
    "for i, j in enumerate(preprocessed['Month']):\n",
    "    addlist.append(Month_to_num(j))\n",
    "preprocessed['Month'] = addlist\n",
    "\n",
    "addlist = []\n",
    "for i, j in enumerate(preprocessed['VisitorType']):\n",
    "    addlist.append(Month_to_num(j))\n",
    "preprocessed['VisitorType'] = addlist\n",
    "\n",
    "addlist = []\n",
    "for i, j in enumerate(preprocessed['Weekend']):\n",
    "    addlist.append(Month_to_num(j))\n",
    "preprocessed['Weekend'] = addlist\n",
    "\n",
    "addlist = []\n",
    "for i, j in enumerate(preprocessed['Revenue']):\n",
    "    addlist.append(Month_to_num(j))\n",
    "preprocessed['Revenue'] = addlist\n",
    "\n",
    "for i in preprocessed.columns:\n",
    "    preprocessed[i] = pd.to_numeric(preprocessed[i], errors='raise')\n",
    "\n",
    "print(preprocessed)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ca05fe789cf17ab3",
   "metadata": {},
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "code",
   "id": "a64c29fcca7de65f",
   "metadata": {},
   "source": [
    "# affinity propagation clustering - aan de hand van documentatie - NU HEEL SLOOM\n",
    "from sklearn.cluster import AffinityPropagation, DBSCAN, Birch\n",
    "Data = preprocessed.copy()\n",
    "#Gebruik van sample maakt het proces sneller\n",
    "Sample = Data.sample(n=1000)\n",
    "clustering = AffinityPropagation(random_state=5).fit(Sample)\n",
    "AffinityPropagation(random_state=24)\n",
    "\n",
    "labels = clustering.labels_\n",
    "cluster_centers = clustering.cluster_centers_\n",
    "n_clusters = len(cluster_centers)\n",
    "\n",
    "print(\"Number of clusters:\", n_clusters)\n",
    "print(\"Cluster centers:\\n\", cluster_centers)\n",
    "\n",
    "\n",
    "# DBSCAN clustering\n",
    "#TODO werkt maar de label -1 laat zien dat er een hoop data punten in ruis categorie vallen...\n",
    "clustering2 = DBSCAN(eps=20).fit(Data)\n",
    "labels2 = clustering2.labels_\n",
    "print(\"Labels DBSCAN\", labels2[:50])   \n",
    "\n",
    "#Lijkt me dat beide problemen hier liggen aan de variabelen in de functies\n",
    "\n",
    "# Birch clustering\n",
    "#TODO nog een groot aantal clusters...\n",
    "clustering3 = Birch(n_clusters=None).fit(Data)\n",
    "labels3 = clustering3.labels_\n",
    "print(\"Labels Birch\", labels3[:50])   \n",
    "aantal_clusters = len(set(labels3))\n",
    "print(\"Aantal clusters Birch\", aantal_clusters)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2d8d2baa9a81b136",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "id": "878a2061917b83d8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# manual Silhouette score, is zo volgensmij goed. Moet alleen zoeken hoe ik deze waardes kan pakken uit de labels\n",
    "import numpy as np\n",
    "def Silhouette_score(point, labelSELF, labels, Data):\n",
    "    clusterSELF = Data[labels == labelSELF].to_numpy()\n",
    "    clusters = Data[labels != labelSELF].to_numpy()\n",
    "    afstand = 0\n",
    "\n",
    "    for points in clusterSELF:\n",
    "        if set(points) == set(point):\n",
    "            continue\n",
    "        afstand += np.linalg.norm(point-points)\n",
    "    a = afstand/len(clusterSELF)\n",
    "\n",
    "    lowest = infty\n",
    "    clustr = None\n",
    "    for clust in clusters:\n",
    "        afstand_nearest = 0\n",
    "        for points in clust:\n",
    "            afstand_nearest += np.linalg.norm(point-points)\n",
    "        dis = afstand_nearest/len(clust)\n",
    "        if dis < lowest:\n",
    "            lowest = dis\n",
    "            clustr = clust\n",
    "    b = lowest\n",
    "    return (b-a)/(max(b,a))\n",
    "\n",
    "def Silhouette_scores(x, labels):\n",
    "    n = len(x)\n",
    "    sil_values = []\n",
    "    for i in range(n):\n",
    "        sil_values.append(Silhouette_score(point=x.iloc[i].to_numpy(), labelSELF = labels[i], labels = labels, Data= x))\n",
    "    print(\"Silhouette score:\", sil_values)\n",
    "\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "print(\"Silhouette scores:\")\n",
    "print(f\"Affinity propogation: {Silhouette_scores(Sample, labels)}\")\n",
    "print(f\"DBSCAN: {Silhouette_scores(Data, labels2)}\")\n",
    "print(f\"Birch Clustering: {Silhouette_scores(Data, labels3)}\")\n",
    "print()\n",
    "\n",
    "# Davies Buildin Score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "print(\"Davies Bouldin score:\")\n",
    "print(f\"Affinity propogation: {davies_bouldin_score(Sample, labels)}\")\n",
    "print(f\"DBSCAN: {davies_bouldin_score(Data, labels2)}\")\n",
    "print(f\"Birch Clustering: {davies_bouldin_score(Data, labels3)}\")\n",
    "print()\n",
    "# calinski-harabasz index\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "print(\"Calinski Harabasz score:\")\n",
    "print(f\"Affinity propogation: {calinski_harabasz_score(Sample, labels)}\")\n",
    "print(f\"DBSCAN: {calinski_harabasz_score(Data, labels2)}\")\n",
    "print(f\"Birch Clustering: {calinski_harabasz_score(Data, labels3)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "12deb65d3f7f63eb",
   "metadata": {},
   "source": [
    "Task 5 ALL MANUAL\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2a95a246f6bf2fa2",
   "metadata": {},
   "source": [
    "# dit is de basics, maar idk wat de dimensies van a en b horen te zijn\n",
    "# Euclidean distance\n",
    "def our_euclidean_distance(a, b):\n",
    "    distance = 0\n",
    "    for index, _ in enumerate(a):\n",
    "        distance += (a[index] - b[index]) ** 2\n",
    "    distance = distance**0.5\n",
    "    return distance\n",
    "# Manhattan distance\n",
    "def our_manhattan_distance(a, b):\n",
    "    distance = 0\n",
    "    for index, _ in enumerate(a):\n",
    "        distance += ((a[index] - b[index]) ** 0.5) ** 2\n",
    "    return distance    \n",
    "# Cosine similarity\n",
    "def our_cosine_similarity(a, b):\n",
    "    numerator = 0\n",
    "    denominator_a = 0\n",
    "    denominator_b = 0\n",
    "    for index, _ in enumerate(a):\n",
    "        numerator += a[index] * b[index]\n",
    "        denominator_a += a[index] ** 2\n",
    "        denominator_b += b[index] ** 2\n",
    "    distance = numerator / (denominator_a ** 0.5 * denominator_b ** 0.5)\n",
    "    return distance\n",
    "# Distances effect on dbscan"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
